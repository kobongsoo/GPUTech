{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5909416-a6c3-49ae-9c1f-3daa6b9564f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------\n",
    "# context를 가지고, 바드 혹은 GPT를 이용하여, sLLM 파인튜닝할 질의응답 말뭉치를 만드는 예시임.\n",
    "# -> context 문단들을 수동으로 만들고, 이를 이용하여 바드 혹은 gpt에게, 아래처럼 프롬프트를 만들어서 쿼리하여, 응답을 가지고 말뭉치로 만듬.\n",
    "# 아래 ##문단:을 가지고 10개의 질문과 답변을 ##질문:, ##답변: 쌍 형식으로 만들어주세요. 단 ##질문: 뒤에 숫자는 붙이면 안됩니다.\\n\\n##문단:{context}\"\n",
    "# -> \n",
    "#\n",
    "#-----------------------------------------------------------------------\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "import sys\n",
    "from myutils import seed_everything, GPU_info, mlogging\n",
    "\n",
    "SEED = 111\n",
    "seed_everything(SEED)\n",
    "DEVICE = GPU_info() # GPU 혹은 CPU\n",
    "LOGGER = mlogging(loggername=\"kopora-test\", logfilename='../log/kopora-test.txt') # 로그\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "files = [\"../data11/mpower_doc/moco_context.txt\",] # 컨텍스트 문단들 파일\n",
    "count = 0  # **카운터가 문서에 uid가 되므로, 유일무이한 값므로 지정할것.\n",
    "\n",
    "tcontexts = []\n",
    "tcontextids = []\n",
    "\n",
    "for idx, file_path in enumerate(files):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        data_list = data.split('\\n\\n')  # '\\n\\n' 구분으로 다락 구분\n",
    "        count += 1\n",
    "        \n",
    "        # titles, contextids 임의로 구해서 데이터 프레임 만듬.\n",
    "        for i in range(len(data_list)):\n",
    "            tcontexts.append(data_list[i])\n",
    "            tcontextids.append(count)\n",
    "\n",
    "# 데이터 프레임으로 만듬.\n",
    "df_contexts = pd.DataFrame((zip(tcontexts, tcontextids)), columns = ['context','contextid'])     \n",
    "\n",
    "print(f'len:{len(df_contexts)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fef672-4ea8-4212-a41b-697a9dae03d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contexts['context'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90a04f8-86af-45ec-9f54-5db36b733bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt(context):\n",
    "    #prompt = f'아래 ##문단:을 가지고 10개의 질문과 답변을 ##질문:, ##답변: 쌍 형식으로 만들어주세요. 단 ##질문: 뒤에 숫자는 붙이면 안됩니다.\\n\\n##문단:{context}'\n",
    "    prompt = f'아래 ##문단 내용이 질문에 대한 답변일대, ##질문 문장을 만들고, 아래 문단 내용을 요약해서 ##답변 문장을 만들어 주세요.\\n\\n{context}'\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443b109d-7b8f-4627-b8b8-8e4087bfdeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------\n",
    "# 구글 bard를 이용한 text 생성\n",
    "#\n",
    "# 세션키를 이용하여 구글 bard 테스트 예제\n",
    "# 출처 : https://github.com/dsdanielpark/Bard-API\n",
    "#\n",
    "# token 값얻기\n",
    "# https://bard.google.com/ 방문\n",
    "# 콘솔용 F12\n",
    "# 세션: 애플리케이션 → 쿠키 → 쿠키 값을 복사합니다 __Secure-1PSID.\n",
    "# -> 참고로 반드시 뒤에 .으로 끝나고 .포함해서 길이가 72자임.\n",
    "#------------------------------------------------------------------\n",
    "import json\n",
    "from bardapi import Bard\n",
    "token = 'XXX' # bard 토큰 입력\n",
    "\n",
    "def generate_text_BARD(prompt):\n",
    "    bard = Bard(token=token,timeout=30) # Set timeout in seconds\n",
    "    answer = bard.get_answer(prompt)['content']\n",
    "    return answer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fd96ff-7f04-4d92-89fc-fcc7f4d6b9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------\n",
    "# GPT를 이용한 text 생성\n",
    "#-----------------------------------------\n",
    "import openai\n",
    "\n",
    "# key 지정\n",
    "openai.api_key = \"sk-xxx\"\n",
    "\n",
    "# 모델 - GPT 3.5 Turbo 지정\n",
    "# => 모델 목록은 : https://platform.openai.com/docs/models/gpt-4 참조\n",
    "gpt_model = \"gpt-3.5-turbo\"#\"gpt-4\"#\"gpt-3.5-turbo\" #gpt-4-0314\n",
    "\n",
    "# 메시지 설정\n",
    "MESSAGES:list = []\n",
    "\n",
    "#-----------------------------------------\n",
    "# GPT를 이용한 text 생성\n",
    "#-----------------------------------------\n",
    "def generate_text_GPT(prompt, messages):\n",
    "    \n",
    "    #print(f'len(messages):{len(messages)}') \n",
    "    #print()\n",
    "    \n",
    "    #-------------------------------------------------------\n",
    "    # *** gpt에 메시지는 계속 대화 내용이 유지가 되므로, 비용이 발생함.\n",
    "    # 따라서 최근 2개 대화만 유지함.\n",
    "    #if len(messages) >= 2:\n",
    "    #    messages = messages[len(messages)-2:]  # 최근 2개의 대화만 가져오기\n",
    "    messages = []  # 무조건 최근대화 초기화\n",
    "     #-------------------------------------------------------\n",
    "        \n",
    "    # 사용자 메시지 추가\n",
    "    messages.append( {\"role\": \"user\", \"content\": prompt})\n",
    "    #print(messages)\n",
    "\n",
    "    # ChatGPT-API 호출하기\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=gpt_model,\n",
    "        messages=messages,\n",
    "        max_tokens=1024, # 토큰 수 \n",
    "        temperature=1,  # temperature 0~2 범위 : 작을수록 정형화된 답변, 클수록 유연한 답변(2는 엉뚱한 답변을 하므로, 1.5정도가 좋은것 같음=기본값은=1)\n",
    "        top_p=0.1 # 기본값은 1 (0.1이라고 하면 10% 토큰들에서 출력 토큰들을 선택한다는 의미)\n",
    "    )\n",
    "\n",
    "    #print(response)\n",
    "    #print()\n",
    "    answer = response['choices'][0]['message']['content']\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3541bb97-6437-49da-932a-a47ab899c6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "contextids = df_contexts['contextid'].values.tolist()\n",
    "contexts = df_contexts['context'].values.tolist()\n",
    "\n",
    "examples = []\n",
    "for context in tqdm(contexts[50:]):\n",
    "    #time.sleep(1)\n",
    "    #print(context)\n",
    "    \n",
    "    # prompt 생성\n",
    "    prompt = make_prompt(context)\n",
    "    #print(prompt)\n",
    "    #print()\n",
    "    \n",
    "    answer = generate_text_BARD(prompt) # bard 이용할때\n",
    "    #answer = generate_text_GPT(prompt=prompt, messages=MESSAGES) #chat gpt이용할때\n",
    "    #print(answer)\n",
    "    answer_list = answer.split('\\n\\n')  # '\\n\\n' 구분으로 다락 구분\n",
    "    \n",
    "    doc = {}\n",
    "    doc['context'] = context\n",
    "    doc['qa'] = answer_list\n",
    "                     \n",
    "    examples.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61428dd1-e4b9-4d11-84b6-9a82bdc32983",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40037d85-204f-4e98-8797-07ac13f53075",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0051ee6e-51f7-449d-84a5-08073f6d3739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트로 파일에 저장\n",
    "with open('./data/moco_qa_60.txt', 'w') as f:\n",
    "\n",
    "    # 리스트를 파일에 씁니다.\n",
    "    for item in examples:\n",
    "        #print(item['context'])\n",
    "        #print(item['qa'])\n",
    "        f.write(item['context'] + '\\n\\n')\n",
    "        for qa in item['qa']:\n",
    "            f.write(qa + '\\n')\n",
    "            \n",
    "        f.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf83044-df3e-4f76-800d-2b1e2fb766e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *이후 파일을 열어서, 수동으로 아래처럼 수정함.\n",
    "# -> contexts 들은 \\n\\n\\n 으로 구분함.\n",
    "# -> ##질문: {} \\n ##답변:{} 은 쌍으로 하고, 다른 질문/답변과는 \\n\\n 구분함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f21254-77dd-4cc3-809b-61223006c7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 조작할 파일들을 불러와서 contexts별로 분할\n",
    "count = 0\n",
    "file_path = './data/moco_qa_gpt.txt'\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    data = f.read()\n",
    "    docs = data.split('\\n\\n\\n')  # '\\n\\n\\n' 구분으로 contexts 단락 구분\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8995a2-3207-430c-8f5d-393a51553976",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "contexts = []\n",
    "questions = []\n",
    "answers = []\n",
    "\n",
    "for doc in tqdm(docs):\n",
    "    data1 = doc.split('\\n\\n')\n",
    "    qa_list = data1[1:]\n",
    "\n",
    "    for qa in qa_list:\n",
    "        data2 = qa.split('##답변:')\n",
    "        if len(data2) == 2:\n",
    "            questions.append(data2[0].replace(\"##질문:\", \"\"))\n",
    "            answers.append(data2[1].replace(\"##답변:\", \"\"))\n",
    "            contexts.append(data1[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed47ff7-327a-4ac6-a6ec-510b547d26ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(contexts[1000])\n",
    "print()\n",
    "print(answers[1000])\n",
    "print()\n",
    "print(questions[1000])\n",
    "print()\n",
    "\n",
    "print(f'{len(contexts)} == {len(questions)} == {len(answers)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c39996d-5ed9-48e5-bef2-a6165271b2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "examples = []\n",
    "\n",
    "for context, question, answer in zip(contexts, questions, answers):\n",
    "    doc = {}\n",
    "    doc['question'] = question\n",
    "    doc['context'] = context\n",
    "    doc['answer'] = answer\n",
    "                        \n",
    "    examples.append(doc)\n",
    "                        \n",
    "docs ={}\n",
    "docs['text'] = examples\n",
    "\n",
    "#json 파일로 저장.\n",
    "# JSON 파일을 엽니다.\n",
    "with open(\"./data/moco_qa_summerize_gpt.json\", \"w\") as f:\n",
    "    # 리스트를 JSON으로 변환합니다.\n",
    "    json.dump(docs, f, indent=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f98608-859c-4f12-a7b8-d8d4849a4378",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

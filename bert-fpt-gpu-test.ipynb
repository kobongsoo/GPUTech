{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bd66b12-3efc-49a7-bdeb-739ff11bd456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logfilepath:../log/bwdataset_2022-04-21.log\n",
      "logfilepath:../log/qnadataset_2022-04-21.log\n"
     ]
    }
   ],
   "source": [
    "#====================================================================================\n",
    "# MLM 방식을 이용한 Further pre-traning 방식 구현 예제\n",
    "# 참고 소스 : https://towardsdatascience.com/masked-language-modelling-with-bert-7d49793e5d2c 참조 바람\n",
    "#====================================================================================\n",
    "import torch\n",
    "import copy\n",
    "import os\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import BertTokenizer, BertConfig, BertForMaskedLM, BertTokenizerFast\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from os import sys\n",
    "sys.path.append('..')\n",
    "from myutils import GPU_info, seed_everything, mlogging, AccuracyForMLM, SaveBERTModel\n",
    "\n",
    "#====================================================================================\n",
    "# bitsandbytes 라이브러리 설치\n",
    "# => 8-bit optimizer 사용을 위해 cuda 버전을 확인하고, 해당 버전에 맞는 bitsandbytes 라이브러리 설치함\n",
    "#   Bitsandbytes is a lightweight wrapper around CUDA custom functions, \n",
    "#   in particular 8-bit optimizers and quantization functions.\n",
    "# => 참조 : https://github.com/facebookresearch/bitsandbytes\n",
    "#\n",
    "#!conda list | grep cudatoolkit     # cuda 버전 확인\n",
    "#!pip install bitsandbytes-cuda113  # 해당 버전에 맞는 bitsandbytes 설치 (버전이 11.3 이면, cuda113 으로 설치)\n",
    "#====================================================================================\n",
    "import bitsandbytes as bnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e4a0bcb-930e-45da-bc18-b4f2b5329266",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "# GPU 보다 큰 모델을 FineTuning 하기 위한 방법\n",
    "# -> \"CUDA 메모리 오류\" 문제를 해결하기 위한 몇가지 방법\n",
    "# 참고 : https://medium.com/@bestasoff/how-to-fine-tune-very-large-model-if-it-doesnt-fit-on-your-gpu-3561e50859af\n",
    "################################################\n",
    "#================================================\n",
    "# 1.gkadient_checkpoint 적용\n",
    "# => backprop 하기전, 순차적으로 피드포워드 된 노드들의 값을 모두 메모리에 저장해 두는 대신, \n",
    "# 체크포인트 방식으로, 필요한 노드들의 값만 메모리에 저장해 두는 방식\n",
    "# => 사용법 : model.gradient_checkpointing_enable()\n",
    "#\n",
    "gradient_checkpoint = True\n",
    "#================================================\n",
    "# 2. micro_batch/Gradient accumulation(마이크로 배치&기울기 축적)\n",
    "# => 배치사이즈는 8로 하고, 대신에 accumulation_steps= 4로 해서, 4번 기울기 축적을 누적해서 \n",
    "# 32배치사이즈와 동일한 효과를 주는 방식\n",
    "# => *훈련시간이 1.3배 더 증가함\n",
    "#\n",
    "micro_batch = True\n",
    "micro_batch_size = 8\n",
    "accumulation_steps = 4\n",
    "#================================================\n",
    "# 3. 8bit-adam optimizer 사용\n",
    "# => 기존 32bit Adam 옵티마이져 대신 8bit Aadmin 옵티마이져를 사용하여, 2^32 -> 2^8 으로 메모리를낮춤\n",
    "# => *bert 모델에서 훈련 테스트시 gpu 메모리가 낮아지지는 않았음\n",
    "# => 사용방법 : optimizer = bnb.optim.Adam8bit(model.parameters(), lr=learning_rate, betas=(0.9, 0.995))\n",
    "adam8bit_use = False\n",
    "#================================================\n",
    "# 4. Mixed-precision training(혼합 정밀도 훈련)\n",
    "# => 훈련은 gpu 모델을 이용하는 데신, gpu 모델 크기를 반으로 줄여(FP16) 사용하고,\n",
    "# 대신 optimizer는 cpu 모델을 이용하여 gd를 업데이트 하는 방식\n",
    "# => gpu 모델과 cpu 모델 2개 필요. 훈련시간이 gpu일때 보다 10배정도 증가, \n",
    "# => adam8bit 와 함께 동작시, 'Error an illegal memory access was encountered at line 276 in file /private/home/timdettmers/git/bitsandbytes/csrc/ops.cu' 에러 발생(*원인 모름)\n",
    "mix_precision = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3321a0d-57d3-400b-be05-619e1bf63842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련시킬 말뭉치(사전 만들때 동일한 말뭉치 이용)\n",
    "#input_corpus = \"../korpora/kowiki_20190620/wiki_20190620_mecab_false_0311.txt\"\n",
    "input_corpus = \"../korpora/kowiki_20190620/wiki_20190620_small.txt\"\n",
    "\n",
    "# eval 말뭉치 \n",
    "eval_corpus = \"../korpora/kowiki_20190620/wiki_eval_test.txt\"\n",
    "\n",
    "# 기존 사전훈련된 모델\n",
    "model_path = \"../model/bert/bert-multilingual-cased\"\n",
    "\n",
    "# 기존 사전 + 추가된 사전 파일\n",
    "vocab_path=\"../tokenizer/my_vocab\"\n",
    "#vocab_path=\"../tokenizer/wiki_20190620_nouns_0324\"\n",
    "\n",
    "# 출력\n",
    "OUTPATH = '../model/bert/bert-multilingual-cased-0421/'\n",
    "\n",
    "token_max_len = 128\n",
    "batch_size = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70b2d1d9-41dd-42eb-8886-a92e29b581a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "device: cuda:0\n",
      "cuda index: 0\n",
      "gpu 개수: 1\n",
      "graphic name: NVIDIA A30\n",
      "cuda:0\n",
      "logfilepath:../log/bertfpt3_2022-04-21.log\n"
     ]
    }
   ],
   "source": [
    "device = GPU_info()\n",
    "print(device)\n",
    "\n",
    "#seed 설정\n",
    "seed_everything(222)\n",
    "\n",
    "#logging 설정\n",
    "logger =  mlogging(loggername=\"bertfpt3\", logfilename=\"../log/bertfpt3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd6fad4a-7b5b-4502-93bc-7564f197398e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "special_token_size: 5, tokenizer.vocab_size: 149793\n",
      "vocab_size: 149798\n",
      "tokenizer_len: 149793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../model/bert/bert-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at ../model/bert/bert-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "2022-04-21 13:24:24,042 - bertfpt3 - INFO - ==>*mix_precision 적용=>cpu_model 생성\n"
     ]
    }
   ],
   "source": [
    "# tokeinzier 생성\n",
    "# tokenizer 생성\n",
    "# => BertTokenizer, BertTokenizerFast 둘중 사용하면됨\n",
    "\n",
    "#tokenizer = BertTokenizer(vocab_file=vocab_path, max_len=token_max_len, do_lower_case=False)\n",
    "tokenizer = BertTokenizer.from_pretrained(vocab_path, max_len=token_max_len, do_lower_case=False)\n",
    "# tokenizer = BertTokenizerFast(vocab_file=vocab_file, max_len=token_max_len, do_lower_case=False)\n",
    "\n",
    "\n",
    "# speical 토큰 계수 + vocab 계수 - 이미 vocab에 포함된 speical 토큰 계수(5)\n",
    "vocab_size = len(tokenizer.all_special_tokens) + tokenizer.vocab_size\n",
    "#vocab_size = len(tokenizer.all_special_tokens) + tokenizer.vocab_size - 5 + 1\n",
    "#vocab_size = len(tokenizer.all_special_tokens) + tokenizer.vocab_size - 5\n",
    "print('special_token_size: {}, tokenizer.vocab_size: {}'.format(len(tokenizer.all_special_tokens), tokenizer.vocab_size))\n",
    "print('vocab_size: {}'.format(vocab_size))\n",
    "print('tokenizer_len: {}'.format(len(tokenizer)))\n",
    "\n",
    "# 모델 로딩 further pre-training \n",
    "#config = BertConfig.from_pretrained(model_path)\n",
    "#model = BertForMaskedLM.from_pretrained(model_path, from_tf=bool(\".ckpt\" in model_path), config=config) \n",
    "\n",
    "##############################################################################\n",
    "# mix_precision 적용인 경우 => gpu_Model 사이즈는 반으로 줄임\n",
    "if mix_precision:\n",
    "    model = BertForMaskedLM.from_pretrained(model_path).half()\n",
    "else:\n",
    "    model = BertForMaskedLM.from_pretrained(model_path)\n",
    "\n",
    "#################################################################################\n",
    "# 모델 embedding 사이즈를 tokenizer 크기 만큼 재 설정함.\n",
    "# 재설정하지 않으면, 다음과 같은 에러 발생함\n",
    "# CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)` CUDA 에러가 발생함\n",
    "#  indexSelectLargeIndex: block: [306,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
    "#\n",
    "#     해당 오류는 기존 Embedding(8002, 768, padding_idx=1) 처럼 입력 vocab 사이즈가 8002인데,\n",
    "#     0~8001 사이를 초과하는 word idx 값이 들어가면 에러 발생함.\n",
    "#################################################################################\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.to(device)\n",
    "\n",
    "#############################################################################\n",
    "# mix_precision 적용인 경우 => cpumodel을 하나 생성\n",
    "if mix_precision:\n",
    "    cpu_model = BertForMaskedLM.from_pretrained(model_path)  \n",
    "    cpu_model.resize_token_embeddings(len(tokenizer))\n",
    "    logger.info(f'==>*mix_precision 적용=>cpu_model 생성')\n",
    "    cpu_model.to('cpu')\n",
    "#############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e41cf1f-4010-4348-8921-67d0f21ea09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-21 13:24:24,056 - bertfpt3 - INFO - ==>*micro_batch 적용, accumulation_steps:4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLSid:101, SEPid:102, UNKid:100, PADid:0, MASKid:103\n",
      "*corpus:../korpora/kowiki_20190620/wiki_20190620_small.txt\n",
      "*max_sequence_len:128\n",
      "*mlm_probability:0.15\n",
      "*CLStokenid:101, SEPtokenid:102, UNKtokenid:100, PADtokeinid:0, Masktokeid:103\n",
      "*total_line: 10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a55483e59ec40cb8112132634b4fa6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c409efd8168488bbba54ab344181681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-21 13:24:28,676 - bwpdataset - INFO - ==>[Start] cached file create: ../korpora/kowiki_20190620/cached_lm_BertTokenizer_128_wiki_20190620_small.txt\n",
      "2022-04-21 13:24:28,784 - bwpdataset - INFO - <==[End] Saving features into cached file ../korpora/kowiki_20190620/cached_lm_BertTokenizer_128_wiki_20190620_small.txt [took 0.106 s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*corpus:../korpora/kowiki_20190620/wiki_eval_test.txt\n",
      "*max_sequence_len:128\n",
      "*mlm_probability:0.15\n",
      "*CLStokenid:101, SEPtokenid:102, UNKtokenid:100, PADtokeinid:0, Masktokeid:103\n",
      "*total_line: 114\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87134e0385e0486485b3b7e63e07490d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0918f56663874a3db8d09ce4e8952db1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-21 13:24:28,952 - bwpdataset - INFO - ==>[Start] cached file create: ../korpora/kowiki_20190620/cached_lm_BertTokenizer_128_wiki_eval_test.txt\n",
      "2022-04-21 13:24:28,955 - bwpdataset - INFO - <==[End] Saving features into cached file ../korpora/kowiki_20190620/cached_lm_BertTokenizer_128_wiki_eval_test.txt [took 0.002 s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([   101, 123809,   9551,    107,    103,    107,    103, 126023,    103,\n",
      "        120115, 120169,  23545,    103,  48506,  70672,  30919,    103,    102,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor([   101, 123809,   9551,    107, 135472,    107, 138135, 126023,  11018,\n",
      "        120115, 120169,  23545,  11303,  48506,  70672,  30919,    119,    102,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0])}\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from myutils import MLMDataset\n",
    "\n",
    "#######################################################################\n",
    "# micro_batch_size 적용인 경우에는 batch_size를 micro_batch_size 로 변경함\n",
    "if micro_batch:\n",
    "    batch_size = micro_batch_size\n",
    "    logger.info(f'==>*micro_batch 적용, accumulation_steps:{accumulation_steps}')\n",
    "#######################################################################\n",
    "\n",
    "# 각 스페셜 tokenid를 구함\n",
    "CLStokenid = tokenizer.convert_tokens_to_ids('[CLS]')\n",
    "SEPtokenid = tokenizer.convert_tokens_to_ids('[SEP]')\n",
    "UNKtokenid = tokenizer.convert_tokens_to_ids('[UNK]')\n",
    "PADtokenid = tokenizer.convert_tokens_to_ids('[PAD]')\n",
    "MASKtokenid = tokenizer.convert_tokens_to_ids('[MASK]')\n",
    "print('CLSid:{}, SEPid:{}, UNKid:{}, PADid:{}, MASKid:{}'.format(CLStokenid, SEPtokenid, UNKtokenid, PADtokenid, MASKtokenid))\n",
    "\n",
    "\n",
    "train_dataset = MLMDataset(corpus_path = input_corpus,\n",
    "                           tokenizer = tokenizer, \n",
    "                           CLStokeinid = CLStokenid ,   # [CLS] 토큰 id\n",
    "                           SEPtokenid = SEPtokenid ,    # [SEP] 토큰 id\n",
    "                           UNKtokenid = UNKtokenid ,    # [UNK] 토큰 id\n",
    "                           PADtokenid = PADtokenid,    # [PAD] 토큰 id\n",
    "                           Masktokenid = MASKtokenid,   # [MASK] 토큰 id\n",
    "                           max_sequence_len=token_max_len,  # max_sequence_len)\n",
    "                           mlm_probability=0.15,\n",
    "                           overwrite_cache=True\n",
    "                          )\n",
    "\n",
    "\n",
    "# 학습 dataloader 생성\n",
    "# => tenosor로 만듬\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=batch_size, \n",
    "                          #shuffle=True, # dataset을 섞음\n",
    "                          sampler=RandomSampler(train_dataset, replacement=False), #dataset을 랜덤하게 샘플링함\n",
    "                          num_workers=3\n",
    "                         )\n",
    "\n",
    "#===============================================================================\n",
    "# eval dataloader 생성\n",
    "eval_dataset = MLMDataset(corpus_path = eval_corpus,\n",
    "                          tokenizer = tokenizer, \n",
    "                          CLStokeinid = CLStokenid ,   # [CLS] 토큰 id\n",
    "                          SEPtokenid = SEPtokenid ,    # [SEP] 토큰 id\n",
    "                          UNKtokenid = UNKtokenid ,    # [UNK] 토큰 id\n",
    "                          PADtokenid = PADtokenid,    # [PAD] 토큰 id\n",
    "                          Masktokenid = MASKtokenid,   # [MASK] 토큰 id\n",
    "                          max_sequence_len=token_max_len,  # max_sequence_len)\n",
    "                          mlm_probability=0.15,\n",
    "                          overwrite_cache=True\n",
    "                          )\n",
    "\n",
    "\n",
    "# eval dataloader 생성\n",
    "# => tenosor로 만듬\n",
    "eval_loader = DataLoader(eval_dataset, \n",
    "                         batch_size=batch_size, \n",
    "                         #shuffle=True, # dataset을 섞음\n",
    "                         sampler=RandomSampler(eval_dataset, replacement=False), #dataset을 랜덤하게 샘플링함\n",
    "                         num_workers=3\n",
    "                         )\n",
    "#===============================================================================\n",
    "\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89756e9c-7002-4d63-b2ef-a3431486fb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-21 13:24:28,993 - bertfpt3 - INFO - ==>*mix_precision 적용\n",
      "2022-04-21 13:24:28,996 - bertfpt3 - INFO - ==>*gradient_checkpoint 적용\n",
      "2022-04-21 13:24:28,997 - bertfpt3 - INFO - ==>*micro_batch 적용, accumulation_steps:4\n",
      "2022-04-21 13:24:28,998 - bertfpt3 - INFO - *batch_size:8, epochs:3, lr:3e-05, token_max_len:128\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b27678d121412481520454d9d269ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fed442140bf43b990bb259a0271a8f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1228 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-21 13:25:19,148 - bertfpt3 - INFO - [Epoch 1/3] Iteration 122 -> Train Loss: 3.4217, Train Acc: 0.5849, Val Acc:0.6005459508644222\n",
      "2022-04-21 13:26:01,562 - bertfpt3 - INFO - [Epoch 1/3] Iteration 244 -> Train Loss: 1.8264, Train Acc: 0.5593, Val Acc:0.5486806187443131\n",
      "2022-04-21 13:26:43,997 - bertfpt3 - INFO - [Epoch 1/3] Iteration 366 -> Train Loss: 0.4147, Train Acc: 0.5457, Val Acc:0.599939338792842\n",
      "2022-04-21 13:27:25,305 - bertfpt3 - INFO - [Epoch 1/3] Iteration 488 -> Train Loss: 0.2357, Train Acc: 0.6192, Val Acc:0.6642402183803457\n",
      "2022-04-21 13:28:06,246 - bertfpt3 - INFO - [Epoch 1/3] Iteration 610 -> Train Loss: 0.1450, Train Acc: 0.6998, Val Acc:0.7719138610858356\n",
      "2022-04-21 13:28:48,694 - bertfpt3 - INFO - [Epoch 1/3] Iteration 732 -> Train Loss: 0.1004, Train Acc: 0.8004, Val Acc:0.835304822565969\n",
      "2022-04-21 13:29:27,956 - bertfpt3 - INFO - [Epoch 1/3] Iteration 854 -> Train Loss: 0.0747, Train Acc: 0.8547, Val Acc:0.8650288140734\n",
      "2022-04-21 13:30:10,107 - bertfpt3 - INFO - [Epoch 1/3] Iteration 976 -> Train Loss: 0.0664, Train Acc: 0.8722, Val Acc:0.8762511373976342\n",
      "2022-04-21 13:30:49,950 - bertfpt3 - INFO - [Epoch 1/3] Iteration 1098 -> Train Loss: 0.0588, Train Acc: 0.8879, Val Acc:0.8835304822565969\n",
      "2022-04-21 13:31:31,258 - bertfpt3 - INFO - [Epoch 1/3] Iteration 1220 -> Train Loss: 0.0541, Train Acc: 0.8938, Val Acc:0.8874734607218684\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2034777ecd974bb9a0db6f0e34f69f85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1228 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-21 13:32:16,391 - bertfpt3 - INFO - [Epoch 2/3] Iteration 1342 -> Train Loss: 0.0959, Train Acc: 0.8020, Val Acc:0.8908098271155596\n",
      "2022-04-21 13:32:53,261 - bertfpt3 - INFO - [Epoch 2/3] Iteration 1464 -> Train Loss: 0.0476, Train Acc: 0.8972, Val Acc:0.89171974522293\n",
      "2022-04-21 13:33:30,930 - bertfpt3 - INFO - [Epoch 2/3] Iteration 1586 -> Train Loss: 0.0469, Train Acc: 0.8989, Val Acc:0.8944494995450409\n",
      "2022-04-21 13:34:09,157 - bertfpt3 - INFO - [Epoch 2/3] Iteration 1708 -> Train Loss: 0.0444, Train Acc: 0.9007, Val Acc:0.8962693357597816\n",
      "2022-04-21 13:34:46,099 - bertfpt3 - INFO - [Epoch 2/3] Iteration 1830 -> Train Loss: 0.0435, Train Acc: 0.9019, Val Acc:0.8965726417955717\n",
      "2022-04-21 13:35:25,450 - bertfpt3 - INFO - [Epoch 2/3] Iteration 1952 -> Train Loss: 0.0440, Train Acc: 0.9021, Val Acc:0.8968759478313618\n",
      "2022-04-21 13:36:03,278 - bertfpt3 - INFO - [Epoch 2/3] Iteration 2074 -> Train Loss: 0.0452, Train Acc: 0.9020, Val Acc:0.8971792538671519\n",
      "2022-04-21 13:36:45,127 - bertfpt3 - INFO - [Epoch 2/3] Iteration 2196 -> Train Loss: 0.0423, Train Acc: 0.9047, Val Acc:0.8971792538671519\n",
      "2022-04-21 13:37:21,646 - bertfpt3 - INFO - [Epoch 2/3] Iteration 2318 -> Train Loss: 0.0430, Train Acc: 0.9051, Val Acc:0.8983924780103124\n",
      "2022-04-21 13:38:01,032 - bertfpt3 - INFO - [Epoch 2/3] Iteration 2440 -> Train Loss: 0.0418, Train Acc: 0.9046, Val Acc:0.8980891719745223\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f2e8f2359854892b3b69b97a3f718bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1228 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-21 13:38:49,554 - bertfpt3 - INFO - [Epoch 3/3] Iteration 2562 -> Train Loss: 0.0523, Train Acc: 0.8817, Val Acc:0.8993023961176827\n",
      "2022-04-21 13:39:30,393 - bertfpt3 - INFO - [Epoch 3/3] Iteration 2684 -> Train Loss: 0.0387, Train Acc: 0.9089, Val Acc:0.8993023961176827\n",
      "2022-04-21 13:40:09,794 - bertfpt3 - INFO - [Epoch 3/3] Iteration 2806 -> Train Loss: 0.0425, Train Acc: 0.9049, Val Acc:0.9002123142250531\n",
      "2022-04-21 13:40:51,425 - bertfpt3 - INFO - [Epoch 3/3] Iteration 2928 -> Train Loss: 0.0436, Train Acc: 0.9050, Val Acc:0.8977858659387322\n",
      "2022-04-21 13:41:33,336 - bertfpt3 - INFO - [Epoch 3/3] Iteration 3050 -> Train Loss: 0.0440, Train Acc: 0.9082, Val Acc:0.8977858659387322\n",
      "2022-04-21 13:42:12,743 - bertfpt3 - INFO - [Epoch 3/3] Iteration 3172 -> Train Loss: 0.0427, Train Acc: 0.9086, Val Acc:0.8989990900818926\n",
      "2022-04-21 13:42:53,277 - bertfpt3 - INFO - [Epoch 3/3] Iteration 3294 -> Train Loss: 0.0443, Train Acc: 0.9052, Val Acc:0.9002123142250531\n",
      "2022-04-21 13:43:33,567 - bertfpt3 - INFO - [Epoch 3/3] Iteration 3416 -> Train Loss: 0.0402, Train Acc: 0.9090, Val Acc:0.9008189262966333\n",
      "2022-04-21 13:44:14,369 - bertfpt3 - INFO - [Epoch 3/3] Iteration 3538 -> Train Loss: 0.0415, Train Acc: 0.9086, Val Acc:0.9014255383682135\n",
      "2022-04-21 13:44:54,598 - bertfpt3 - INFO - [Epoch 3/3] Iteration 3660 -> Train Loss: 0.0426, Train Acc: 0.9070, Val Acc:0.9002123142250531\n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "epochs = 3            # epochs\n",
    "learning_rate = 3e-5  # 학습률\n",
    "##################################################\n",
    "\n",
    "##################################################\n",
    "# adam8bit_use & mix_precision 적용\n",
    "if adam8bit_use & mix_precision:\n",
    "    optimizer = bnb.optim.Adam8bit(cpu_model.parameters(), lr=learning_rate, betas=(0.9, 0.995))\n",
    "    logger.info(f'==>*adam8bit_use & mix_precision 적용')\n",
    "# adam8bit만 적용한 경우 \n",
    "elif adam8bit_use:\n",
    "    optimizer = bnb.optim.Adam8bit(model.parameters(), lr=learning_rate, betas=(0.9, 0.995))\n",
    "    logger.info(f'==>*adam8bit_use 적용')\n",
    "# mix_precision 만 적용한 경우 \n",
    "elif mix_precision:\n",
    "     # optimizer 적용\n",
    "    optimizer = AdamW(cpu_model.parameters(), lr=learning_rate, eps=1e-8)\n",
    "    logger.info(f'==>*mix_precision 적용')\n",
    "else:\n",
    "    # optimizer 적용\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate, eps=1e-8) \n",
    "##################################################\n",
    "\n",
    "# 총 훈련과정에서 반복할 스탭\n",
    "total_steps = len(train_loader)*epochs\n",
    "warmup_steps = total_steps * 0.1 #10% of train data for warm-up\n",
    "\n",
    "# 손실률 보여줄 step 수\n",
    "p_itr = int(len(train_loader)*0.1)  \n",
    "    \n",
    "# step마다 모델 저장\n",
    "save_steps = int(total_steps * 0.5)\n",
    "    \n",
    "# 스캐줄러 생성\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=warmup_steps, \n",
    "                                            num_training_steps=total_steps)\n",
    "\n",
    "itr = 1\n",
    "total_loss = 0\n",
    "total_len = 0\n",
    "total_correct = 0\n",
    "total_test_correct = 0\n",
    "total_test_len = 0\n",
    "    \n",
    "list_train_loss = []\n",
    "list_train_acc = []\n",
    "list_validation_acc = []\n",
    "\n",
    "##################################################\n",
    "# gradient_checkpoint 설정한 경우 \n",
    "if gradient_checkpoint:\n",
    "    model.gradient_checkpointing_enable()\n",
    "    logger.info(f'==>*gradient_checkpoint 적용')\n",
    "##################################################\n",
    "    \n",
    "if micro_batch:\n",
    "    logger.info(f'==>*micro_batch 적용, accumulation_steps:{accumulation_steps}')\n",
    "   \n",
    "logger.info(f'*batch_size:{batch_size}, epochs:{epochs}, lr:{learning_rate}, token_max_len:{token_max_len}')\n",
    "\n",
    "model.zero_grad()# 그래디언트 초기화\n",
    "for epoch in tqdm(range(epochs)):\n",
    "\n",
    "    model.train() # 훈련모드로 변환\n",
    "    if mix_precision:\n",
    "        cpu_model.train()\n",
    "        \n",
    "    for batch_idx, data in enumerate(tqdm(train_loader)):\n",
    "    \n",
    "        #optimizer.zero_grad()\n",
    "         \n",
    "        # 입력 값 설정\n",
    "        input_ids = data['input_ids'].to(device)\n",
    "        attention_mask = data['attention_mask'].to(device)\n",
    "        token_type_ids = data['token_type_ids'].to(device)       \n",
    "        labels = data['labels'].to(device)\n",
    "        #print('Labels:{}'.format(labels))\n",
    "        \n",
    "        # 모델 실행\n",
    "        outputs = model(input_ids=input_ids, \n",
    "                       attention_mask=attention_mask,\n",
    "                       token_type_ids=token_type_ids,\n",
    "                       labels=labels)\n",
    "        \n",
    "        # 출력값 loss,logits를 outputs에서 얻어옴\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        #print('Loss:{}, logits:{}'.format(loss, logits))\n",
    "        \n",
    "        #######################################################################################\n",
    "        # micro_batch 사용 하는 경우\n",
    "        if micro_batch:\n",
    "            loss = loss / accumulation_steps\n",
    "        #######################################################################################\n",
    "        \n",
    "        # optimizer 과 scheduler 업데이트 시킴\n",
    "        loss.backward()   # backward 구함\n",
    "            \n",
    "        #######################################################################################\n",
    "        # micro_batch 사용 하는 경우\n",
    "        if micro_batch:\n",
    "            if ((batch_idx + 1) % accumulation_steps == 0) or (batch_idx + 1 == len(train_loader)):\n",
    "                # mix_precison 사용인경우\n",
    "                if mix_precision:\n",
    "                    for p_gpu, p_cpu in zip(model.parameters(), cpu_model.parameters()):\n",
    "                        p_cpu.grad = p_gpu.grad.cpu().to(torch.float32)\n",
    "                        #p_cpu.grad = copy.copy(p_gpu.grad.cpu().to(torch.float32))   \n",
    "             \n",
    "                    model.zero_grad()\n",
    "                    optimizer.step()\n",
    "                    scheduler.step()  # 학습률 감소\n",
    "                    model.load_state_dict(cpu_model.state_dict())\n",
    "                    cpu_model.zero_grad()\n",
    "                else:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)   \n",
    "                    optimizer.step()  # 가중치 파라미터 업데이트(optimizer 이동)\n",
    "                    scheduler.step()  # 학습률 감소\n",
    "                    model.zero_grad()# 그래디언트 초기화\n",
    "        else: \n",
    "                # mix_precison 사용인경우\n",
    "                if mix_precision:\n",
    "                    for p_gpu, p_cpu in zip(model.parameters(), cpu_model.parameters()):\n",
    "                        p_cpu.grad = p_gpu.grad.cpu().to(torch.float32)\n",
    "                        #p_cpu.grad = copy.copy(p_gpu.grad.cpu().to(torch.float32)) \n",
    "                        \n",
    "                    model.zero_grad()\n",
    "                    optimizer.step()\n",
    "                    scheduler.step()  # 학습률 감소\n",
    "                    model.load_state_dict(cpu_model.state_dict())\n",
    "                    cpu_model.zero_grad()\n",
    "                else:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)   # 그래디언트 클리핑 (gradient vanishing이나 gradient exploding 방지하기 위한 기법)\n",
    "                    optimizer.step()  # 가중치 파라미터 업데이트(optimizer 이동)\n",
    "                    scheduler.step()  # 학습률 감소\n",
    "                    model.zero_grad()# 그래디언트 초기화\n",
    "  \n",
    "        \n",
    "        #######################################################################################\n",
    "           \n",
    "        # ***further pretrain 에는 손실률 계산을 넣지 않음\n",
    "        # 정확도 계산은 no_grade 시켜서, 계산량을 줄임.\n",
    "        \n",
    "        # => torch.no_grad()는 gradient을 계산하는 autograd engine를 비활성화 하여 \n",
    "        # 필요한 메모리를 줄이고, 연산속도를 증가시키는 역활을 함\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            # 손실률 계산\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            #===========================================\n",
    "            # 정확도(Accurarcy) 계산\n",
    "            correct = AccuracyForMLM(logits, labels, attention_mask)\n",
    "            total_correct += correct.sum().item() \n",
    "            total_len += attention_mask.sum().item() # 단어 총 수는 attension_mask가 1(True) 인 것들의 합\n",
    "            #=========================================\n",
    "                \n",
    "            # 주기마다 test(validataion) 데이터로 평가하여 손실류 계산함.\n",
    "            if itr % p_itr == 0:\n",
    "                \n",
    "                train_loss = total_loss/p_itr\n",
    "                train_acc = total_correct/total_len\n",
    "                       \n",
    "                ####################################################################\n",
    "                # 주기마다 eval(validataion) 데이터로 평가하여 손실류 계산함.\n",
    "                # 평가 시작\n",
    "                model.eval()\n",
    "\n",
    "                #for data in tqdm(eval_loader):\n",
    "                for data in eval_loader:\n",
    "                    # 입력 값 설정\n",
    "                    input_ids = data['input_ids'].to(device)\n",
    "                    attention_mask = data['attention_mask'].to(device)\n",
    "                    token_type_ids = data['token_type_ids'].to(device)       \n",
    "                    labels = data['labels'].to(device)\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        # 모델 실행\n",
    "                        outputs = model(input_ids=input_ids, \n",
    "                                       attention_mask=attention_mask,\n",
    "                                       token_type_ids=token_type_ids,\n",
    "                                       labels=labels)\n",
    "\n",
    "                        # 출력값 loss,logits를 outputs에서 얻어옴\n",
    "                        #loss = outputs.loss\n",
    "                        logits = outputs.logits\n",
    "\n",
    "                        #===========================================\n",
    "                        # 정확도(Accurarcy) 계산\n",
    "                        correct = AccuracyForMLM(logits, labels, attention_mask)\n",
    "                        total_test_correct += correct.sum().item() \n",
    "                        total_test_len += attention_mask.sum().item()  # 단어 총 수는 attension_mask가 1(True) 인 것들의 합\n",
    "                        #=========================================\n",
    "\n",
    "                val_acc = total_test_correct/total_test_len\n",
    "                    \n",
    "                logger.info('[Epoch {}/{}] Iteration {} -> Train Loss: {:.4f}, Train Acc: {:.4f}, Val Acc:{}'.format(epoch+1, epochs, itr, train_loss, train_acc, val_acc))\n",
    "                    \n",
    "                list_train_loss.append(train_loss)\n",
    "                list_train_acc.append(train_acc)\n",
    "                list_validation_acc.append(val_acc)\n",
    "                 \n",
    "                # 변수들 초기화    \n",
    "                total_loss = 0\n",
    "                total_len = 0\n",
    "                total_correct = 0\n",
    "                total_test_correct = 0\n",
    "                total_test_len = 0\n",
    "                ####################################################################\n",
    "\n",
    "            #if itr % save_steps == 0:\n",
    "                #전체모델 저장\n",
    "                #SaveBERTModel(model, tokenizer, OUTPATH, epochs, learning_rate, batch_size)\n",
    "        \n",
    "        itr+=1\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51b2ad73-f4b8-46b7-82a5-d2d54ed35cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport copy\\nfor p_gpu, p_cpu in zip(model.parameters(), cpu_model.parameters()):\\n    #p1 = p_gpu.grad.cpu().to(torch.float32)\\n    print(p_gpu.grad.cpu().to(torch.float32))\\n    p_cpu.grad = copy.copy(p_gpu.grad.cpu().to(torch.float32))   \\n    print(p_cpu.grad)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import copy\n",
    "for p_gpu, p_cpu in zip(model.parameters(), cpu_model.parameters()):\n",
    "    #p1 = p_gpu.grad.cpu().to(torch.float32)\n",
    "    print(p_gpu.grad.cpu().to(torch.float32))\n",
    "    p_cpu.grad = copy.copy(p_gpu.grad.cpu().to(torch.float32))   \n",
    "    print(p_cpu.grad)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b517c6d1-246c-417a-92e8-b310dd4c2f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프로 loss 표기\n",
    "#!pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(list_train_loss, label='Train Loss')\n",
    "#plt.plot(list_train_acc, label='Train Accuracy')\n",
    "#plt.plot(list_validation_acc, label='Eval Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(list_train_acc, label='Train Accuracy')\n",
    "plt.plot(list_validation_acc, label='Eval Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59891576-ff4e-4826-b5b3-90468005a80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "#save_model(model, tokenizer, OUTPATH, epochs, learning_rate, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111fac71-a6d8-4eb6-bc77-e1bca6b19225",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
